---
layout: post   
title: Pytorch To Onnx Convert Error     
subtitle: Bug Fix       
tags: [programming, pytorch, onnx]  
comments: true  
---   

## Torch.inverse() Can't export ONNX

ONNX에서 torch.inverse (역함수 행렬) 구하는 연산이 지원되지 않아 변환시 에러가 발생한다.  
아래 코드를 통해 torch.inverse()를 대체할 수 있다.  
단, batch 별로 serial 하게 수행하기 때문에 병렬 연산엔 효율적이진 못하다. 

* Code 

```python

import torch

device = torch.device("cpu" if not torch.cuda.is_available() else "cuda:0")

############### Torch Inverse #################

def cof1(M, index):
    zs = M[:index[0]-1, :index[1]-1]
    ys = M[:index[0]-1, index[1]:]
    zx = M[index[0]:, :index[1]-1]
    yx = M[index[0]:, index[1]:]
    s = torch.cat([zs, ys], axis=1)
    x = torch.cat([zx, yx], axis=1)
    return torch.det(torch.cat([s, x], axis=0))


def alcof(M, index):
    return pow(-1, index[0]+index[1]) * cof1(M, index)

def adj(M):

    result = torch.zeros(M.shape).to(device)
    for i in range(1, M.shape[0]+1):
        for j in range(1, M.shape[1]+1):
            result[j-1][i-1] = alcof(M,[i, j])
    return result

def invmat(M):

    result = torch.zeros(M.shape).to(device)
    for batch in range(M.shape[0]):
        result[batch] = 1.0/torch.det(M[batch])*adj(M[batch])
    return result

if __name__ == "__main__":

    M = torch.randn((3, 4, 4))
    print(M)
    print(torch.inverse(M))
    print(invmat(M))

```

* requirements
  * opset_version == 14 로 설정한다 (이하 버전에서는 torch.det() opperation이 지원되지 않음)
    
```python
torch.onnx.export(model, (inputs, ), 
                  "model.onnx", 
                  input_names=['inputs'],
                  output_names=['outputs'],
                  opset_version=14)
```


## F.grid_sample() Can't export ONNX

완전히 같은 값은 아니지만 precision < 5 이하의 작은 오차로 비슷한 연산으로 대체할 수 있다.

* Code

```python
############# Torch Grid Sampler ##################
import torch
import torch.nn.functional as F

def bilinear_grid_sample(im, grid, align_corners=False):
    """Given an input and a flow-field grid, computes the output using input
    values and pixel locations from grid. Supported only bilinear interpolation
    method to sample the input pixels.

    Args:
        im (torch.Tensor): Input feature map, shape (N, C, H, W)
        grid (torch.Tensor): Point coordinates, shape (N, Hg, Wg, 2)
        align_corners {bool}: If set to True, the extrema (-1 and 1) are
            considered as referring to the center points of the input’s
            corner pixels. If set to False, they are instead considered as
            referring to the corner points of the input’s corner pixels,
            making the sampling more resolution agnostic.

    Returns:
        torch.Tensor: A tensor with sampled points, shape (N, C, Hg, Wg)
    """
    n, c, h, w = im.shape
    gn, gh, gw, _ = grid.shape
    assert n == gn

    x = grid[:, :, :, 0]
    y = grid[:, :, :, 1]

    if align_corners:
        x = ((x + 1) / 2) * (w - 1)
        y = ((y + 1) / 2) * (h - 1)
    else:
        x = ((x + 1) * w - 1) / 2
        y = ((y + 1) * h - 1) / 2

    x = x.view(n, -1)
    y = y.view(n, -1)

    x0 = torch.floor(x).long()
    y0 = torch.floor(y).long()
    x1 = x0 + 1
    y1 = y0 + 1

    wa = ((x1 - x) * (y1 - y)).unsqueeze(1)
    wb = ((x1 - x) * (y - y0)).unsqueeze(1)
    wc = ((x - x0) * (y1 - y)).unsqueeze(1)
    wd = ((x - x0) * (y - y0)).unsqueeze(1)

    # Apply default for grid_sample function zero padding
    im_padded = F.pad(im, pad=[1, 1, 1, 1], mode='constant', value=0)
    padded_h = h + 2
    padded_w = w + 2
    # save points positions after padding
    x0, x1, y0, y1 = x0 + 1, x1 + 1, y0 + 1, y1 + 1

    # Clip coordinates to padded image size
    x0 = torch.where(x0 < 0, torch.tensor(0).to(device), x0)
    x0 = torch.where(x0 > padded_w - 1, torch.tensor(padded_w - 1).to(device), x0)
    x1 = torch.where(x1 < 0, torch.tensor(0).to(device), x1)
    x1 = torch.where(x1 > padded_w - 1, torch.tensor(padded_w - 1).to(device), x1)
    y0 = torch.where(y0 < 0, torch.tensor(0).to(device), y0)
    y0 = torch.where(y0 > padded_h - 1, torch.tensor(padded_h - 1).to(device), y0)
    y1 = torch.where(y1 < 0, torch.tensor(0).to(device), y1)
    y1 = torch.where(y1 > padded_h - 1, torch.tensor(padded_h - 1).to(device), y1)

    im_padded = im_padded.view(n, c, -1)

    x0_y0 = (x0 + y0 * padded_w).unsqueeze(1).expand(-1, c, -1)
    x0_y1 = (x0 + y1 * padded_w).unsqueeze(1).expand(-1, c, -1)
    x1_y0 = (x1 + y0 * padded_w).unsqueeze(1).expand(-1, c, -1)
    x1_y1 = (x1 + y1 * padded_w).unsqueeze(1).expand(-1, c, -1)

    Ia = torch.gather(im_padded, 2, x0_y0)
    Ib = torch.gather(im_padded, 2, x0_y1)
    Ic = torch.gather(im_padded, 2, x1_y0)
    Id = torch.gather(im_padded, 2, x1_y1)

    return (Ia * wa + Ib * wb + Ic * wc + Id * wd).reshape(n, c, gh, gw)

# Toy model including blinear_grid_sampler
class Sampler(torch.nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, x, grid):
        return bilinear_grid_sample(x, grid, align_corners=False)


if __name__ == "__main__":

    # sample input and grid
    x = torch.randn(1, 4, 10, 10)
    grid = 2 * torch.rand(1, 8, 8, 2) - 1  # scale as (-1, 1)

    # reference output
    ref = F.grid_sample(x, grid, align_corners=False)
    # substitute output
    out = bilinear_grid_sample(x, grid, align_corners=False)
    # almost the same
    diff = out-ref
    torch.set_printoptions(precision=5, sci_mode=False)
    print(diff)

```

