---
layout: post  
title: TOWARDS GAN BENCHMARKS WHICH REQUIRE GENERALIZATION    
subtitle: AI Paper Review      
tags: [ai, ml, computer vision, GAN, metrics, evaluation, benchmarks]    
comments: true  
---  

ICLR 2019, GoogleBrain 에서 기재한 논문이다. 

많은 evaluation metrics은 image generation의 벤치마크로 공통적으로 사용되고 있다.
단순히 학습셋을 memorizing 하는 것이 SOTA를 고려하는 것보다 더 좋은 점수를 얻게 만드는 것은 매우 문제이다. 
평가 메트릭이 다음과 같이 작동하지 않게 필수 조건을 명확히 해야한다.
함수를 추정하려면 모델에는 많은 샘플이 필요하다. 이런 매트릭을 찾기 위해 우리는 신경망 측면에서 분포를 구별하도록 훈련된 Neural Network Divergence (NND)로 전환해야한다.
벤치마크는 훈련 세트 암기로 승리할 수 없지만 여전히 지각적으로 상관관계가 있고 샘플에서만 계산할 수 있다. 
평가를 위해 NND를 사용하는 과거 작업을 조사하고 이러한 아이디어를 기반으로 예시적인 블랙박스 메트릭을 구현한다.
실험적 검증을 통해 이것이 다양성, 샘플 품질 및 일반화를 효과적으로 측정할 수 있음을 보여준다. 

[Paper Link](https://arxiv.org/pdf/2001.03653.pdf)  

## Introduction
머신 러닝에서는 목표를 향한 진행 상황을 직접 측정하기 어려운 경우가 많다.
그렇기 때문에, 평가하기 쉽고 마지막 task를 제공하는 proxy로 사용할 표준화된 벤치마크 작업을 정의하는 것이 유용하다.
이것은 부적절한 기준선이나 평가 실수를 줄임으로써 훨씬 더 강련한 개선 주장을 가능하게 한다.
벤치마크의 진행을 통해 최종 작업에 유용한 결과 발견과 방법이 나오길 바란다.
이 접근 방식을 사용하려면 벤치마크 작업이 다음 두 가지 속성을 충족해야 한다.

1. 개선에 대한 강력한 주장이 이루어질 수 있도록 간단하고 객관적인 평가절차를 정의해야 한다.
높은 점수를 얻기 위한 **모든 제한 없는 방법(ex: 테스트 세트 남용)을 명확하게 정의** 해야 한다.
2. 벤치마크에서 향상된 성능을 위해서는 최종 작업에 도움이 될 수 있는 통찰력이 필요하다.
 벤치마크는 구성에 따라 **최종 작업에 내재된 어려움의 종류 중 최소한의 일부를 반영** 해야 한다.

벤치마크는 적어도 사소한 것이 아니여야한다. 명백히 금지된 방법을 제외하고 우리는 어떻게 임의적으로 높은 점수를 얻을 수 있는 지 사전 지식을 알면 안된다. 
유용한 벤치마크 방법은 final task를 고려한 evaluation metric을 사용하는 것이다. 

이 논문은 최근의 generative modeling의 natural image 생성을 다룬다.
아이디어는 일반적이지만 GAN 모델의 evaluation을 향상시키기를 바란다. 

## Background
논문 전체에서 저자는 분포 간의 비유사성 개념을 지정하는 통계적 발산으로 평가 메트릭을 캐스팅했다.
따라서 generative modeling의 목표는 이런 발산을 최소화하고, divergence 의 선택은 마지막 task의 특징을 반영한다.

### Evaluation Metrics for Models of Natural Images
* Inception Score (IS)
    * 기준: 생성된 영상의 품질, 생성된 영상의 다양성
    * Inception 모델에서 예측한 label의 Variation이 클 수록 Score가 높도록 설계
    
* Frechet Inception Distance (FID)
* Log-likelihood